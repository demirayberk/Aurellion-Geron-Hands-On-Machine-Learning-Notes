{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 Fundementals Of Machine Learning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "### What is machine learning.\n",
    "\n",
    "- Machine learning is the science (and art) of programming so computers can learn from data.\n",
    "\n",
    "- Machine learning is the field of study that gives computers the ability to leran without being explicitle programmed\n",
    "\n",
    "- A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T , as measured by P improves with experience E.\n",
    "\n",
    "### Why machine learning.\n",
    "\n",
    "- Machine learning is a technique to be used when traditional programming techniques are not enough.\n",
    "\n",
    "- For example if you want to detect spam filters with traditional programming techniques, you have to write rules for ever.\n",
    "\n",
    "- In contrast if you use a machine learning algorithm you just need to provide the computer with the user tagged spam filters, and computer will find the patterns between this inputs and outputs.\n",
    "\n",
    "- Also with machine learning models you can automate the process\n",
    "\n",
    "- Another area where machine learning shines is for ptorblems that either too complex for traditional approaches or have no known algorithm.\n",
    "\n",
    "- Additionally, ml algorithms can help humans to learn for instance once spam filter has been trained on enough spam it can easily be inspected to reveal the list of words and combinations of words that it believes are the best predictors of spam Sometimes this will reveal unsuspected correlations and trends.\n",
    "\n",
    "- Applying Ml techniques to dig into large amounts of data can help discover patterns that were not immediately apparent. This is called ***Data Mining***\n",
    "\n",
    "- *Summary* Ml is great for;\n",
    "    - Problems for which existing solutions require a lot of fine tuning or long lists of rules.\n",
    "    - Complex problems for which using a traditionlal approach yields no good solution.\n",
    "    - Machine learning can adapt to new data\n",
    "    - Getting insights about complex problems and large amounts of data.\n",
    "\n",
    "- There are 4 major categories\n",
    "    - Supervised Learning\n",
    "    - Unsupervised Learning\n",
    "    - Semisupervised Learning\n",
    "    - Reinforcement Learning\n",
    "### Supervised Learning\n",
    "\n",
    "- In supervised learning the training set you feed to the algorithm includes the desired solutions.\n",
    "\n",
    "Most Commonly used algorithms;\n",
    "- k-Nearest Neighbors,\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "- Support Vector Machines\n",
    "- Decision Trees and Random Forests\n",
    "- Neural networks\n",
    "### Unsupervised Learning\n",
    "- The data is unlabeled algorithm tries to learn without a teacher.\n",
    "\n",
    "Most used algorigthms;\n",
    "\n",
    "- Clustering\n",
    "    - K means\n",
    "    - DBSCAN\n",
    "    - Hierarchical Cluster Analysis(HCA)\n",
    "- Anomaly detection and dimensionality reduction.\n",
    "    - One class SVM\n",
    "    - Isolation Forest.\n",
    "- Visualization and dimensionality reduction\n",
    "    - Principal component analysis (PCA)\n",
    "    - Kernel PCA\n",
    "    - Locally Linear Embedding (lle)\n",
    "    - t-distributed stochasting neighbor embedding (t-SNE)\n",
    "- Association rule learning\n",
    "    - Apriory\n",
    "    - Eclat\n",
    "\n",
    "- For exxample you may want to run a clustering algorithm to try to detect groups of similar visitors. At no point do you tell the algorithm which group a visitor belongs to\n",
    "\n",
    "- Visualization algorithms are also good examples of unsupervised learning algorithms. you feed them a lot of complex and unlkabeled data, and they output a 2D or 3D representation of your data that can easily be plotted. These algorithms try to preserve as much structure as they can so that you can orginized and perhaps identify unsuspected patterns.\n",
    "\n",
    "- A related task is dimensionality reduction . Whic has a goal to simplyfy the data without losing too much information.\n",
    "\n",
    "It is often a good idea to try to reduce the dimension of your training data using dimensionality reduction algorithm before you feed it to another machine learniung algorithm it will run much faster the data will take up less disk and memory space and in some cases it m,ay also perform better.\n",
    "\n",
    "- Another useful task is anomaly detection it can be used to prevent cretid card fraud, catching manufacturing defects. Automatically removing outliers.\n",
    "\n",
    "- Finally another common unsupervised task is association rule learning which goal is to dig into large amounts of data and discover interesting relations between attributes.\n",
    "\n",
    "### Semisupervised Learning\n",
    "\n",
    "- Since labeling data is usually time consuming and costly, you will often have plenty of unlabeled instances and few labeled instances. Some algorithms can deal with data that's partially labeled. This is called semisupervised learning.\n",
    "\n",
    "### Reinforcement Learning\n",
    "\n",
    "- The learning system, called an egent in this context can observe the environment select and perform actions and get rewards in return (or penalties in the form of negative rewards) It must then learn by itself what is the best strategy called a *policy* to get the most reward over time. A policy defines what action the agent should choose when it is in a given situation.\n",
    "\n",
    "### Batch learning\n",
    "\n",
    "- If you want a batch learning system to know about new data you need to train a new version of the system from scratch on the full dataset then stop the old system and replace it with the new one.\n",
    "\n",
    "- It simply updates the data and traina new version of the system\n",
    "\n",
    "- Training on updated dataset requires lots of computing resources if you have lots of data and you automate your system ot train from scratch every day, it will end up costiong you a lot of money if the amount of data is huge it may even be impossible to use a batch learning algorithm\n",
    "\n",
    "### Online learning\n",
    "\n",
    "-  New data is learning on the fly.\n",
    "\n",
    "- The model keeps learning as new data comes in\n",
    "\n",
    "- Online learning algorithms can laso be used to train systems on huge datasets that cannot fit in one machine's main memory.\n",
    "\n",
    "\n",
    "### Instance Based Versus Model Based Learning.\n",
    "#### Instance Based Learning.\n",
    "\n",
    "- Most trivial form of learning is simply to learn by heart if you were to create a spam filter this way it would just flag all emails that are identical to emails that have already been flagged by the useers not the worst solution buyt certanly not the best.\n",
    "\n",
    "#### Model-based learning\n",
    "\n",
    "- Another way to generalize from a set of examples is to build a model of these examples and than use that model to make predictions. This is called model-based learning.\n",
    "\n",
    "- In summary steps are\n",
    "\n",
    "    - You studied the data\n",
    "    - You selected a model\n",
    "    - You trained it on the training data(the learning algorithm searched for the model parameter values that minimize a cost function)\n",
    "    - Finally you applied the model to make prediction on new cases(this is inference) hoping that this model will generalize well.\n",
    "### Challenges of machine learning\n",
    "#### Insufficient Quantity of Training Data.\n",
    "\n",
    "- It takes a lot of data for most Machine Learning algorithms to work properly. Even for very simple problems you typically need thousands of examples and for complex problems such as image or speech recognition you may need millions of examples.\n",
    "\n",
    "- Data is more important than the algorithm!!@!@!\n",
    "\n",
    "#### Nonrepresentative Training Data\n",
    "\n",
    "- In order to generalÄ±ze well. It is crucial that your training data be representetive of the new cases you want ot generalize to.\n",
    "\n",
    "- By using a nonrepresentative training set we trained a model that is unlikely to make accurate prediction, especially for very poor and very rich countries.\n",
    "\n",
    "- It is crucial to use a training set that is representative of the cases you want to generalize to. This is often harder than it sounds: if the sample is too small, you will have samling noise, but even very large samples can be nonrepresentative if the sampling method is flawed. This is called sampling bias.\n",
    "\n",
    "#### Poor Quality Data\n",
    "\n",
    "- If your training data is full of errors, outliers and noise. It will make it harder for the system to detect the underlying patterns. The truth is most data scientists spend a significant part of their time doing just cleaning the data.\n",
    "    - If some instances are clearly outliers it may help to simply discard them or try to fix errors manually\n",
    "\n",
    "    - If some instances are missing a few featires you must decide whether you want to ignore this attribute altogether ignore these instances fill in the missing values.\n",
    "\n",
    "#### Irrelevant Features\n",
    "\n",
    "- A critical part of the success of a machine learning project is coming up with a good set of features to train on. This process called feature engineering involves the fallowing steps:\n",
    "\n",
    "    - Feature selection\n",
    "    - Feature extraction\n",
    "    - Creating new features by gathering new data\n",
    "\n",
    "#### Overfitting the Training Data\n",
    "\n",
    "- Say you re visiting a foreign country and the taxi driver rips you off. You might be tempted to say taht all taxi drivers in that country are thieves\n",
    "\n",
    "- Overgeneralizing is something that we humans do all too often, and unfortunately machines can fall into the same trap if we are not careful. In machine learning we call it overfitting.\n",
    "\n",
    "- It basicaly is model performs well on the training data but it does not generalize well.\n",
    "\n",
    "- Constraining a model to make it simpler and reduce the risk of overfitting is called regularization. For example tweaking the slope in the linear regression model.\n",
    "\n",
    "Simple ways to reduce overfitting;\n",
    "    \n",
    "- Simplify the model by selecting one with fewer parameters.\n",
    "- Gather more data\n",
    "- Reduce the noise in the training data.\n",
    "\n",
    "#### Underfitting the Training Data\n",
    "\n",
    "- Opposite of the underfitting.\n",
    "\n",
    "Here are the main options for ficing this problem;\n",
    "\n",
    "- Select a more powerful model, with more parameters\n",
    "- Feed better features to the learning algorithm\n",
    "- Reduce the constraints on the model.\n",
    "\n",
    "### Testing and Validating.\n",
    "\n",
    "- In order to understand the generalization you split the data in order to monitor its performance\n",
    "\n",
    "- Generally 0.2 test and 0.8 training.\n",
    "\n",
    "### Hyperparameter Tuning and Model Selection\n",
    "\n",
    "- You hold out part of the training set to evaluate several candidate models and selsect the best one. The new held out set is called the *validation set*. You train multiple models with various hyperparameters on the reduced training set. and you select the model that performs best on the validation set. After this holdout validation process, you train the best model on the full training set and this gives you the final model\n",
    "\n",
    "- This solution usually works quite well. However if the validation set is too small, then model evalutations will be imprecise you may end up selecting a suboptimal; model by mistake. Conversely if the validation set is too large then the remaining training set will be much smaller than the full training set. Why ius this bad well since the final model will be trained on the full training set it is not ideal to compare candidate models trained on a much smaller training set . ITwould be like selecting the faastest sprinter to participate in a marathon.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

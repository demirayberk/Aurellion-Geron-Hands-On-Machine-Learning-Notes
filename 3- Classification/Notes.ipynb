{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter3 Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- We will investigate classification and we will look at the MNIST dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayber\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "\n",
    "mnist = fetch_openml(\"mnist_784\", version=1)\n",
    "\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1701ef1b8b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X.values[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label\n",
    "\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This datasset is already shuffled learning algorithms are sensitive to the order of the training instances and they perform poorly if they get many similar instances in a row. Shuffling the dataset ensures that this won't happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a binary classifier\n",
    "\n",
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets pic a classifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgf_clf = SGDClassifier(random_state=42)\n",
    "sgf_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayber\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgf_clf.predict([some_digit])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Measures\n",
    "\n",
    "#### Measuring accuracy using cross-validation.\n",
    "\n",
    "- Let's use the cross_val_score() function to evaluate our SGDClassifier model using K-fold cross-validation with three folds.Remember that K-fold cross-validation means splitting the training set into K folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95035, 0.96035, 0.9604 ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgf_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This in not suprising since 10 percent of the images are 5s. so if you always guess that an image is not a 5 you will be right about 90 percent of the time.\n",
    "\n",
    "This Demonstrates why accuracy is generally not the preferred performance measure for classifiers especially when you are dealing with skewed datasets.\n",
    "\n",
    "### Confision Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred = cross_val_predict(sgf_clf ,X_train, y_train_5, cv=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53892,   687],\n",
       "       [ 1891,  3530]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall\n",
    "\n",
    "- Confusion matrix gives yuou a lot of information but sometimes you may prefer a more concise metric. An interesting one to lok at is the accuracy of the postigve prediction this is called the precision of the classifier.\n",
    "\n",
    "- Precision = TP/ (TP+FP)\n",
    "\n",
    "- A trivial way to have perfect precision is to make one single positiver prediction and ensure it is correct. But this would not be very useful since the classifier would ignore all but one positive instance so precision is typically used along with another metric named _recall_ also called sensitivity or the true positive rate; this is the ratio of positive instances that are correctylt detected by the classifier.\n",
    "\n",
    "- False ; this is the real, Negative; this is the prediction\n",
    "\n",
    "- In simpler words, precision answers the question: \"What proportion of positive identifications was actually correct?\"\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370879772350012"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_train_5, y_train_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6511713705958311"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7325171197343846"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score favors classifiers that have similar precision and recall. This is not always what you wnat. In some contexts you mostly care about precisiion and in other contexts you really care about recall. For example if you trained a classifier to detect videos that are safe for kids, you would probably prefer a classifier that rejects many good videos (low recall), but keeps only safe ones (high precision), rather than a classifier that has a much higher recall but lets a few really bad videos show up in your product (In such cases you may even want to add a human pipeline to check classifiers video selection). On the other hand suppose you train a classifier to detect shoplifters in surveillance immages it is probably fine if your classifier has only 30 percent precision as long as it has 00 recall.\n",
    "\n",
    "Ungirtunately you can't have it both ways increasing precision reduces recall and vice verco this is calle dthe precision recall trade ff.\n",
    "\n",
    "\n",
    "### Precision/Recall Trade-off\n",
    "\n",
    "- Wen you try to adjust precision to be a better value recall increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayber\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2164.22030239])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scores = sgf_clf.decision_function([some_digit])\n",
    "y_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see it is fairly easy to create a classifier with vurtyakky any precision you wnat: just set a high enough threshold and you;re done but sait not so fast a high precision classifier is not very useful if its recall is too low\n",
    "\n",
    "- If someone says lets reach 00 precision you should ask as what recall."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ROC Curve\n",
    "\n",
    "- Reciever operating characteristic curve is another common tool used with binary classifiers.\n",
    "\n",
    "- It is very similar to the precision recall curve but instead of plotting precision versus reca;; the ROC cureve plots the true positeve rate against the (Recall) against the false positive rate. The FPR is the ratio of negative instances that are incorrectyle classified as positive . It is equal to 1 the true negative rate which is the ratio of negative insatances that are correctyly classified as negative. The TNR is also called specifity. ROC curve plots the sensitivity versys specifity.\n",
    "\n",
    "- One way to compare classifiers is to measure the area untder the curve (AUC) A perfect classifier will have a ROC AUUC equal to 1 whereaes pure random ROC AUC scikit learn provides a fucntion to compute the ROC AUC\n",
    "\n",
    "- Since thr ROC curve is similar to precision/racal curve you may wonder how to decide thish one to use. As a rule of thimb you should prefer the PR curve whenever the poistive class is rare or when you care more about the false positives the false negatives. Otherwise use the ROC curve for ezamle looking at the previous ROC curve and the ROC AUC score you. In contrast the PR curve makes it clear that the classifier has room for improvement (the curve could be clopser to the top corner)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification.\n",
    "\n",
    "- Whereas binary classifiers distinguish between two classes multiclass classifiers can distinguish between more than two classes.\n",
    "\n",
    "- Some algorithms such as SGD classifiers Random forest classifiers and naive bayes classifiers are capable of hangling multiple classes natively.\n",
    "\n",
    "- You can also use multiclass classifications using logistic regression or support vecore machine classifiers you can perform multiclass classification.\n",
    "\n",
    "- Another strategy is to train a binary classifier for every pair of digit, one to distinguish 0s and 1s another to distinguish -1s and 2s another Then when you want to classify an image you get the decision score from each class ifier for that image and you the class whose class ouputs the highest score.\n",
    "\n",
    "- For most bunary classifaction algorithms ONE VERSUS THE RESTR STRAGEGY is preferred\n",
    "\n",
    "- Scikit learn detects when you try to use a binary classification algorithm for a multiclass classification task and it automatically runs OvR or OvO deoending on teh algoruthm. Let's try with a suport vectore machine .\n",
    "\n",
    "- In order to creatre a multiclass classifier using the OvR strategy based on an SVC;\n",
    "\n",
    "- Always look at the confusion matrix.\n",
    "\n",
    "### Error Analysis\n",
    "\n",
    "- analyze the types of errors it makes.\n",
    "\n",
    "- Look at the confusion matrix.\n",
    "\n",
    "- After you create confusion matrix, you can divide every element by its sum of the corresponding label to see what percent you got right and wrong and which one is most confusing the algorithm.\n",
    "\n",
    "- By this you can also tell when you made a prediction was it right? and how many of them were right.\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
